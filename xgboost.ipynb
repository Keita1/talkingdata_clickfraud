{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/submission'),\n",
       " PosixPath('data/train_day8_3to16_FE.feather'),\n",
       " PosixPath('data/sample_submission.csv'),\n",
       " PosixPath('data/train_day9_3to16_FE.feather'),\n",
       " PosixPath('data/train_sample.csv'),\n",
       " PosixPath('data/train_day7_3to16_FE.feather'),\n",
       " PosixPath('data/dtree.dot'),\n",
       " PosixPath('data/test_FE.feather'),\n",
       " PosixPath('data/val_idxs.p'),\n",
       " PosixPath('data/mean_enc_df'),\n",
       " PosixPath('data/validation')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "seed=42\n",
    "PATH = Path('data')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(rf,X_val,y_val):\n",
    "    y_val_pred = rf.predict_proba(X_val)[:,1]\n",
    "    return roc_auc_score(y_val,y_val_pred)\n",
    "\n",
    "def permutation_importances(rf,X_val,y_val,metric):\n",
    "    baseline = metric(rf,X_val,y_val)\n",
    "    imp=[]\n",
    "    for col in X_val.columns:\n",
    "        save = X_val[col].copy()\n",
    "        X_val[col] = np.random.permutation(X_val[col])\n",
    "        m = metric(rf,X_val,y_val)\n",
    "        print(f'Score after {col} perm: {m:.5f}')\n",
    "        X_val[col] = save\n",
    "        imp.append(baseline-m)\n",
    "    return np.array(imp)\n",
    "\n",
    "def get_sample_timeseries(filename,sz):\n",
    "    df = get_feather(filename)\n",
    "    sample_idx =np.random.permutation(df.shape[0])\n",
    "    sample_idx=sorted(sample_idx[:sz])\n",
    "    df = df.loc[sample_idx,:].reset_index().drop('index',axis=1)\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "def prediction_score(rf,train_df,y_train,val_df,y_val):\n",
    "    y_train_pred = rf.predict_proba(train_df)[:,1]\n",
    "    print(f'Train AUC: {roc_auc_score(y_train, y_train_pred)}')\n",
    "    y_val_pred = rf.predict_proba(val_df)[:,1]\n",
    "    val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "    print(f'Val AUC: {roc_auc_score(y_val, y_val_pred)}')\n",
    "    return val_auc\n",
    "def get_val_by_name(name):\n",
    "    val_df = pd.read_feather(i)\n",
    "    y_val = val_df.is_attributed\n",
    "    val_df.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    gc.collect()\n",
    "    return val_df,y_val\n",
    "def get_train(sz=3000000):\n",
    "    train_df=get_sample_timeseries('train_day8_3to16_FE.feather',sz)\n",
    "    y_train = train_df.is_attributed\n",
    "    train_df.drop(cols_to_drop,axis=1,inplace=True)\n",
    "    gc.collect()\n",
    "    return train_df,y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['is_attributed','ip','day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/validation/val3.feather',\n",
       " 'data/validation/val2.feather',\n",
       " 'data/validation/val0.feather',\n",
       " 'data/validation/val1.feather']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_names = [str(i) for i in list((PATH/'validation').iterdir())]\n",
    "val_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,y_train = get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.961706\tvalid-auc:0.952353\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[20]\ttrain-auc:0.973846\tvalid-auc:0.964133\n",
      "[40]\ttrain-auc:0.977108\tvalid-auc:0.966103\n",
      "[60]\ttrain-auc:0.981407\tvalid-auc:0.96793\n",
      "[80]\ttrain-auc:0.983716\tvalid-auc:0.968611\n",
      "[100]\ttrain-auc:0.985235\tvalid-auc:0.969131\n",
      "[120]\ttrain-auc:0.986866\tvalid-auc:0.969194\n",
      "[140]\ttrain-auc:0.988198\tvalid-auc:0.969369\n",
      "[160]\ttrain-auc:0.989261\tvalid-auc:0.969275\n",
      "[180]\ttrain-auc:0.990185\tvalid-auc:0.969167\n",
      "[200]\ttrain-auc:0.990998\tvalid-auc:0.969031\n",
      "Stopping. Best iteration:\n",
      "[137]\ttrain-auc:0.988004\tvalid-auc:0.969374\n",
      "\n",
      "Train AUC: 0.9880038792179244. Val AUC: 0.9693738584339497. Best ite: 138\n",
      "[0]\ttrain-auc:0.961706\tvalid-auc:0.952633\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[20]\ttrain-auc:0.973846\tvalid-auc:0.964361\n",
      "[40]\ttrain-auc:0.977108\tvalid-auc:0.966179\n",
      "[60]\ttrain-auc:0.981407\tvalid-auc:0.96774\n",
      "[80]\ttrain-auc:0.983716\tvalid-auc:0.968488\n",
      "[100]\ttrain-auc:0.985235\tvalid-auc:0.968965\n",
      "[120]\ttrain-auc:0.986866\tvalid-auc:0.969074\n",
      "[140]\ttrain-auc:0.988198\tvalid-auc:0.969211\n",
      "[160]\ttrain-auc:0.989261\tvalid-auc:0.969119\n",
      "[180]\ttrain-auc:0.990185\tvalid-auc:0.969047\n",
      "[200]\ttrain-auc:0.990998\tvalid-auc:0.968933\n",
      "Stopping. Best iteration:\n",
      "[137]\ttrain-auc:0.988004\tvalid-auc:0.969249\n",
      "\n",
      "Train AUC: 0.9880038792179244. Val AUC: 0.9692491399657687. Best ite: 138\n",
      "[0]\ttrain-auc:0.961706\tvalid-auc:0.953676\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[20]\ttrain-auc:0.973846\tvalid-auc:0.965092\n",
      "[40]\ttrain-auc:0.977108\tvalid-auc:0.966875\n",
      "[60]\ttrain-auc:0.981407\tvalid-auc:0.968417\n",
      "[80]\ttrain-auc:0.983716\tvalid-auc:0.969153\n",
      "[100]\ttrain-auc:0.985235\tvalid-auc:0.969751\n",
      "[120]\ttrain-auc:0.986866\tvalid-auc:0.969896\n",
      "[140]\ttrain-auc:0.988198\tvalid-auc:0.970119\n",
      "[160]\ttrain-auc:0.989261\tvalid-auc:0.970084\n",
      "[180]\ttrain-auc:0.990185\tvalid-auc:0.970033\n",
      "[200]\ttrain-auc:0.990998\tvalid-auc:0.969965\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-auc:0.988531\tvalid-auc:0.970146\n",
      "\n",
      "Train AUC: 0.9885308312392529. Val AUC: 0.9701456236409576. Best ite: 148\n",
      "[0]\ttrain-auc:0.961706\tvalid-auc:0.952758\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[20]\ttrain-auc:0.973846\tvalid-auc:0.964292\n",
      "[40]\ttrain-auc:0.977108\tvalid-auc:0.965903\n",
      "[60]\ttrain-auc:0.981407\tvalid-auc:0.967716\n",
      "[80]\ttrain-auc:0.983716\tvalid-auc:0.968483\n",
      "[100]\ttrain-auc:0.985235\tvalid-auc:0.969162\n",
      "[120]\ttrain-auc:0.986866\tvalid-auc:0.969366\n",
      "[140]\ttrain-auc:0.988198\tvalid-auc:0.969637\n",
      "[160]\ttrain-auc:0.989261\tvalid-auc:0.969566\n",
      "[180]\ttrain-auc:0.990185\tvalid-auc:0.969563\n",
      "[200]\ttrain-auc:0.990998\tvalid-auc:0.969433\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-auc:0.988531\tvalid-auc:0.969684\n",
      "\n",
      "Train AUC: 0.9885308312392529. Val AUC: 0.9696845096182835. Best ite: 148\n",
      "CPU times: user 43min 58s, sys: 2min 14s, total: 46min 13s\n",
      "Wall time: 12min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {'colsample_bytree': 0.7, \n",
    "          'eval_metric': 'auc', \n",
    "          'learning_rate': 0.1, \n",
    "          'max_depth': 4, \n",
    "          'min_child_weight': 100, \n",
    "          'objective': 'binary:logistic', \n",
    "          'seed': seed, \n",
    "          'subsample': 0.9500000000000001,\n",
    "          'scale_pos_weight': 100,\n",
    "          'tree_method': 'gpu_hist'}\n",
    "\n",
    "dtrain = xgb.DMatrix(train_df,y_train)\n",
    "del train_df,y_train\n",
    "gc.collect()\n",
    "\n",
    "for i in val_names:           \n",
    "    val_df,y_val = get_val_by_name(i)\n",
    "    dval = xgb.DMatrix(val_df,y_val)\n",
    "    \n",
    "    del val_df,y_val\n",
    "    gc.collect()\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "    xgb_model = xgb.train(params, dtrain, 2000, watchlist,\n",
    "                      verbose_eval=20, \n",
    "                      early_stopping_rounds=70)\n",
    "\n",
    "    train_pred = xgb_model.predict(dtrain,ntree_limit=xgb_model.best_ntree_limit)\n",
    "    val_pred = xgb_model.predict(dval,ntree_limit=xgb_model.best_ntree_limit)\n",
    "\n",
    "    train_loss = roc_auc_score(dtrain.get_label(),train_pred)\n",
    "    val_loss = roc_auc_score(dval.get_label(),val_pred)\n",
    "    print(f'Train AUC: {train_loss}. Val AUC: {val_loss}. Best ite: {xgb_model.best_ntree_limit}')\n",
    "\n",
    "    del dval\n",
    "    xgb_model.__del__()\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['is_attributed','ip','day']\n",
    "train_df,y_train = get_train()\n",
    "\n",
    "val_name = 'data/validation/val3.feather'\n",
    "val_df,y_val = get_val_by_name(val_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "val_losses=[]\n",
    "ites=[]\n",
    "\n",
    "dtrain = xgb.DMatrix(train_df,y_train)\n",
    "\n",
    "dval = xgb.DMatrix(val_df,y_val)\n",
    "\n",
    "del train_df,y_train,val_df,y_val\n",
    "gc.collect()\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "\n",
    "\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dval, 'valid')]\n",
    "    xgb_model = xgb.train(params, dtrain, 2000, watchlist,\n",
    "                      verbose_eval=False, \n",
    "                      early_stopping_rounds=100)\n",
    "\n",
    "    train_pred = xgb_model.predict(dtrain,ntree_limit=xgb_model.best_ntree_limit)\n",
    "    val_pred = xgb_model.predict(dval,ntree_limit=xgb_model.best_ntree_limit)\n",
    "\n",
    "    train_loss = roc_auc_score(y_train,train_pred)\n",
    "    val_loss = roc_auc_score(y_val,val_pred)\n",
    "    val_losses.append(val_loss)\n",
    "    ites.append(xgb_model.best_ntree_limit)\n",
    "    print(f'Train AUC: {train_loss}. Val AUC: {val_loss}. Best ite: {xgb_model.best_ntree_limit}')\n",
    "\n",
    "    del dval\n",
    "    xgb_model.__del__()\n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(space,max_evals=5):\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "        # trials=trials, \n",
    "        max_evals=max_evals)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    #'n_estimators': hp.quniform('n_estimators', 50, 500, 5),\n",
    "#     'max_depth': hp.choice('max_depth', np.arange(5, 10, dtype=int)),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.6, 1, 0.05),\n",
    "    'gamma': hp.quniform('gamma', 0, 1, 0.05),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', np.arange(100,200, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(100,300, dtype=int)),\n",
    "    'scale_pos_weight': hp.choice('scale_pos_weight', np.arange(100,200, dtype=int)),\n",
    "    'learning_rate': 0.2,\n",
    "    'eval_metric': 'auc', \n",
    "    'objective': 'binary:logistic', \n",
    "    'seed': seed,'tree_method':'gpu_hist'\n",
    "}\n",
    "best_hyperparams = optimize(space,max_evals=400)\n",
    "print(\"The best hyperparameters are: \")\n",
    "print(best_hyperparams)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
