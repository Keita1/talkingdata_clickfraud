{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed=42\n",
    "PATH = Path('data')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop=['is_attributed','ip','day','device']\n",
    "train_filename = 'train_day8_3to16_nextclick_FE.feather'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_names = [str(i) for i in list((PATH/'validation').iterdir())]\n",
    "val_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'train_day8_3to16_nextclick_FE.feather'\n",
    "train_df,y_train = get_train(cols_to_drop,train_filename,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':'auc',\n",
    "        'learning_rate': 0.2,\n",
    "        'scale_pos_weight':120,\n",
    "        'verbose': 50,\n",
    "        \"device\" : \"gpu\",\n",
    "        \"max_bin\":63,\n",
    "        \"gpu_use_dp\":False,\n",
    "        \n",
    "    }\n",
    "\n",
    "val_names=['data/validation/val2.feather']\n",
    "for i in val_names:           \n",
    "    val_df,y_val = get_val_by_name(cols_to_drop,i)    \n",
    "\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(train_df, label=y_train,categorical_feature=[0,1,2,3]), 2000,\n",
    "                          lgb.Dataset(val_df, label=y_val),\n",
    "                          verbose_eval=50, \n",
    "                          early_stopping_rounds=50)\n",
    "    train_pred = lgb_model.predict(train_df,lgb_model.best_iteration)\n",
    "    val_pred = lgb_model.predict(val_df,lgb_model.best_iteration)\n",
    "\n",
    "    train_loss = roc_auc_score(y_train,train_pred)\n",
    "    val_loss = roc_auc_score(y_val,val_pred)\n",
    "    print(f'Train AUC: {train_loss}. Val AUC: {val_loss}. Best ite: {lgb_model.best_iteration}')\n",
    "\n",
    "    del val_df,y_val\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric':'auc',\n",
    "        'learning_rate': 0.2,\n",
    "        'scale_pos_weight':120,\n",
    "        'verbose': 50,\n",
    "        \"device\" : \"cpu\"\n",
    "    }\n",
    "\n",
    "val_names=['data/validation/val2.feather']\n",
    "for i in val_names:           \n",
    "    val_df,y_val = get_val_by_name(cols_to_drop,i)    \n",
    "\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(train_df, label=y_train), 2000,\n",
    "                          lgb.Dataset(val_df, label=y_val),\n",
    "                          verbose_eval=50, \n",
    "                          early_stopping_rounds=50)\n",
    "    train_pred = lgb_model.predict(train_df,lgb_model.best_iteration)\n",
    "    val_pred = lgb_model.predict(val_df,lgb_model.best_iteration)\n",
    "\n",
    "    train_loss = roc_auc_score(y_train,train_pred)\n",
    "    val_loss = roc_auc_score(y_val,val_pred)\n",
    "    print(f'Train AUC: {train_loss}. Val AUC: {val_loss}. Best ite: {lgb_model.best_iteration}')\n",
    "\n",
    "    del val_df,y_val\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "lgb.plot_importance(lgb_model,ax=ax,height=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,y_train = get_train(cols_to_drop,train_filename,10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_name = 'data/validation/val2.feather'\n",
    "val_df,y_val = get_val_by_name(cols_to_drop,val_name)\n",
    "print(val_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "val_losses=[]\n",
    "ites=[]\n",
    "\n",
    "\n",
    "\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "\n",
    "\n",
    "    lgb_model = lgb.train(params, lgb.Dataset(train_df, label=y_train), 2000,\n",
    "                          lgb.Dataset(val_df, label=y_val),\n",
    "                          verbose_eval=False, \n",
    "                          early_stopping_rounds=50)\n",
    "\n",
    "    \n",
    "\n",
    "    train_pred = lgb_model.predict(train_df,lgb_model.best_iteration)\n",
    "    val_pred = lgb_model.predict(val_df,lgb_model.best_iteration)\n",
    "\n",
    "    train_loss = roc_auc_score(y_train,train_pred)\n",
    "    val_loss = roc_auc_score(y_val,val_pred)\n",
    "    val_losses.append(val_loss)\n",
    "    ites.append(lgb_model.best_iteration)\n",
    "    print(f'Train AUC: {train_loss}. Val AUC: {val_loss}. Best ite: {lgb_model.best_iteration}')\n",
    "\n",
    "    del lgb_model\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    return {'loss': val_loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(space,max_evals=5):\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "        # trials=trials, \n",
    "        max_evals=max_evals)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space = {\n",
    "    #'n_estimators': hp.quniform('n_estimators', 50, 500, 5),\n",
    "#     'max_depth': hp.choice('max_depth', np.arange(5, 10, dtype=int)),\n",
    "    'subsample': hp.quniform('subsample', 0.65, .9, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.6, .75, 0.05),\n",
    "    'gamma': hp.quniform('gamma', 0, 0.7, 0.05),\n",
    "    'max_leaf_nodes': hp.choice('max_leaf_nodes', np.arange(115,139, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(150,250, dtype=int)),\n",
    "    'scale_pos_weight': hp.choice('scale_pos_weight', np.arange(140,175, dtype=int)),\n",
    "    'learning_rate': 0.2,\n",
    "    'eval_metric': 'auc', \n",
    "    'objective': 'binary:logistic', \n",
    "    'seed': seed,'tree_method':'gpu_hist'\n",
    "}\n",
    "best_hyperparams = optimize(space,max_evals=100)\n",
    "print(\"The best hyperparameters are: \")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_names = [str(i) for i in list((PATH/'validation').iterdir())]\n",
    "val_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,y_train = get_train(cols_to_drop,train_filename,10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_name = ['data/validation/val2.feather']\n",
    "val_df,y_val=[],[]\n",
    "for name in val_name:\n",
    "    temp = get_val_by_name(cols_to_drop,name) \n",
    "    val_df.append(temp[0])\n",
    "    y_val.append(temp[1])\n",
    "    \n",
    "final_df = pd.concat([train_df] + val_df,ignore_index=True)\n",
    "final_y = pd.concat([y_train] + y_val,ignore_index=True)\n",
    "\n",
    "del train_df,y_train,val_df,y_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.to_feather(PATH/'final_train.feather')\n",
    "# final_y.Series.to_csv(PATH/'final_y.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.read_feather(PATH/'final_train.feather')\n",
    "# final_y = pd.Series.read_csv(PATH/'final_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=2\n",
    "# params = {'colsample_bytree': 0.7000000000000001, \n",
    "#           'eval_metric': 'auc', \n",
    "#           'gamma': 0.15000000000000002, \n",
    "#           'learning_rate': 0.2/ratio, \n",
    "#           'max_leaf_nodes': 137, \n",
    "#           'min_child_weight': 234, \n",
    "#           'objective': 'binary:logistic', \n",
    "#           'scale_pos_weight': 174, \n",
    "#           'seed': 42, \n",
    "#           'subsample': 0.65, \n",
    "#           'tree_method': 'gpu_hist'}\n",
    "params = {'colsample_bytree': 0.65, \n",
    "          'eval_metric': 'auc', \n",
    "          'gamma': 0.6000000000000001, \n",
    "          'learning_rate': 0.2/ratio, \n",
    "          'max_leaf_nodes': 123, \n",
    "          'min_child_weight': 226, \n",
    "          'objective': 'binary:logistic', \n",
    "          'scale_pos_weight': 153, \n",
    "          'seed': 42, \n",
    "          'subsample': 0.9, \n",
    "#           'tree_method': 'gpu_hist'\n",
    "          'tree_method': \"hist\"\n",
    "         }\n",
    "n_ite = (50+5)*ratio\n",
    "\n",
    "dtrain = xgb.DMatrix(final_df,final_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del final_df,final_y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(params, dtrain, n_ite,[(dtrain, 'train'), (dtrain, 'valid')],\n",
    "                  verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dtrain\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "xgb.plot_importance(xgb_model,ax=ax,height=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.save_model(str(PATH/'xgb_FE_best_more.model'))\n",
    "xgb_model.__del__()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model = xgb.Booster({'nthread': 4})  # init model\n",
    "xgb_model.load_model(str(PATH/'xgb_FE_best_more.model'))  # load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_feather('test_nextclick_FE.feather')\n",
    "\n",
    "test.drop(cols_to_drop[1:],axis=1,inplace=True)\n",
    "\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(test)\n",
    "\n",
    "del test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(PATH/'sample_submission.csv')\n",
    "sub.is_attributed = pred\n",
    "sub.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(PATH/'submission'/'XGB_FE_day89_ratio2_10mil_moreite.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 212,
   "position": {
    "height": "235px",
    "left": "1280px",
    "right": "20px",
    "top": "134.997px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
