{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/blending'),\n",
       " WindowsPath('data/ipapp.pkl'),\n",
       " WindowsPath('data/submission'),\n",
       " WindowsPath('data/test.csv'),\n",
       " WindowsPath('data/test_nextclick_FE.feather'),\n",
       " WindowsPath('data/train_day8_3to16_nextclick_FE.feather'),\n",
       " WindowsPath('data/train_day9_3to16_nextclick_FE.feather'),\n",
       " WindowsPath('data/validation')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from utils import *\n",
    "\n",
    "seed=42\n",
    "PATH = Path('data')\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred = pd.read_csv(PATH/'submission'/'imbalanced_data.csv') # .9728\n",
    "fm_pred =  pd.read_csv(PATH/'submission'/'wordbatch_fm_ftrl.csv')# .9769\n",
    "xgb_pred = pd.read_csv(PATH/'submission'/'XGB_FE_day89_ratio2_10mil_moreite.csv') # .9777\n",
    "lgb_pred = pd.read_csv(PATH/'submission'/'sub-it200102.csv') # .9811?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pred = xgb_pred.is_attributed*0.4 + nn_pred.is_attributed*0.3+fm_pred.is_attributed*0.3\n",
    "final_pred = lgb_pred.is_attributed*0.5 + nn_pred.is_attributed*0.1+fm_pred.is_attributed*0.2 + xgb_pred.is_attributed*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_pred = xgb_pred.is_attributed*0.25 + nn_pred.is_attributed*0.25+fm_pred.is_attributed*0.25 + lgb_pred.is_attributed*0.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = xgb_pred.copy()\n",
    "sub.is_attributed = final_pred\n",
    "# sub.to_csv(PATH/'submission'/'blending_4_models_even.csv',index=False)\n",
    "sub.to_csv(PATH/'submission'/'blending_bestlgb_5122.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>is_attributed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18790464</th>\n",
       "      <td>18790464</td>\n",
       "      <td>0.108887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790465</th>\n",
       "      <td>18790465</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790466</th>\n",
       "      <td>18790467</td>\n",
       "      <td>0.019053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790467</th>\n",
       "      <td>18790466</td>\n",
       "      <td>0.027378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790468</th>\n",
       "      <td>18790468</td>\n",
       "      <td>0.001248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          click_id  is_attributed\n",
       "18790464  18790464       0.108887\n",
       "18790465  18790465       0.000395\n",
       "18790466  18790467       0.019053\n",
       "18790467  18790466       0.027378\n",
       "18790468  18790468       0.001248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use chunksize in read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(PATH/'test.csv',chunksize=3000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   click_id      ip  app  device  os  channel           click_time\n",
      "0         0    5744    9       1   3      107  2017-11-10 04:00:00\n",
      "1         1  119901    9       1   3      466  2017-11-10 04:00:00\n",
      "2         2   72287   21       1  19      128  2017-11-10 04:00:00\n",
      "3         3   78477   15       1  13      111  2017-11-10 04:00:00\n",
      "4         4  123080   12       1  13      328  2017-11-10 04:00:00\n",
      "         click_id     ip  app  device  os  channel           click_time\n",
      "3000000   3000000  94836   15       1  19      259  2017-11-10 04:53:29\n",
      "3000001   3000001   5314   18       1  13      379  2017-11-10 04:53:29\n",
      "3000002   3000002  52186   25       1  13      259  2017-11-10 04:53:29\n",
      "3000003   3000003   2821   20       1  13      478  2017-11-10 04:53:29\n",
      "3000004   3000004   5314   18       1  19      107  2017-11-10 04:53:29\n",
      "         click_id     ip  app  device  os  channel           click_time\n",
      "6000000   6000001  55910    2       1  22      364  2017-11-10 05:55:22\n",
      "6000001   6000000  88233   18       1  13      379  2017-11-10 05:55:22\n",
      "6000002   6000002  82472    2       1  19      435  2017-11-10 05:55:22\n",
      "6000003   6000003   5314   15       1  15      480  2017-11-10 05:55:22\n",
      "6000004   6000004  39782    3       2  42      402  2017-11-10 05:55:22\n",
      "         click_id      ip  app  device  os  channel           click_time\n",
      "9000000   9000000   43511   18       1  17      265  2017-11-10 09:56:22\n",
      "9000001   9000001   62048   14       1  19      480  2017-11-10 09:56:22\n",
      "9000002   9000002  122760   12       1  17      105  2017-11-10 09:56:22\n",
      "9000003   9000003    9161    9       1  13      466  2017-11-10 09:56:22\n",
      "9000004   9000004  123729   20       1  19      478  2017-11-10 09:56:22\n",
      "          click_id      ip  app  device  os  channel           click_time\n",
      "12000000  12000000  115119   15       1  13      315  2017-11-10 10:53:51\n",
      "12000001  12000001    6313    9       1  22      215  2017-11-10 10:53:51\n",
      "12000002  12000002   52999    9       1  18      244  2017-11-10 10:53:51\n",
      "12000003  12000003  111601    3       1  13      409  2017-11-10 10:53:51\n",
      "12000004  12000004   38684    3       1  13      480  2017-11-10 10:53:51\n",
      "          click_id      ip  app  device  os  channel           click_time\n",
      "15000000  15000000  103036    9       1  19      466  2017-11-10 13:50:33\n",
      "15000001  15000001   58600    1       1  13      153  2017-11-10 13:50:33\n",
      "15000002  15000003   42307   14       1  35      379  2017-11-10 13:50:33\n",
      "15000003  15000002   66000    2       1  19      236  2017-11-10 13:50:33\n",
      "15000004  15000004   32746   14       1  25      442  2017-11-10 13:50:33\n",
      "          click_id      ip  app  device  os  channel           click_time\n",
      "18000000  18000000   75825   18       1  28      107  2017-11-10 14:44:36\n",
      "18000001  18000001    3218   12       1  17      140  2017-11-10 14:44:36\n",
      "18000002  18000002   59763   18       1   8      107  2017-11-10 14:44:36\n",
      "18000003  18000003  108816   26       1  11      121  2017-11-10 14:44:36\n",
      "18000004  18000004  112775   23       1  19      153  2017-11-10 14:44:36\n"
     ]
    }
   ],
   "source": [
    "for chunk in temp_df:\n",
    "    print(chunk.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy memmap: Mapping new features (in pickles or feather) in existing memmap\n",
    "\n",
    "Read this first: https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.memmap.html\n",
    "\n",
    "numpy.memmap: Create a memory-map to an array stored in a binary file on disk.\n",
    "\n",
    "Memory-mapped files are used for accessing small segments of large files on disk, without reading the entire file into memory\n",
    "\n",
    "\n",
    "The memmap object can be used anywhere an ndarray is accepted. Given a memmap fp, isinstance(fp, numpy.ndarray) returns True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv(PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df[['ip','app']].to_pickle(PATH/'ipapp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.drop(['ip','app'],axis=1,inplace=True)\n",
    "temp_df.to_csv('test2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_id</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>channel</th>\n",
       "      <th>click_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>466</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>128</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>111</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>328</td>\n",
       "      <td>2017-11-10 04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   click_id  device  os  channel           click_time\n",
       "0         0       1   3      107  2017-11-10 04:00:00\n",
       "1         1       1   3      466  2017-11-10 04:00:00\n",
       "2         2       1  19      128  2017-11-10 04:00:00\n",
       "3         3       1  13      111  2017-11-10 04:00:00\n",
       "4         4       1  13      328  2017-11-10 04:00:00"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = 10000000     # border between train/test in pickle (length of our train)\n",
    "start_skip = 0   # if we want strip our train\n",
    "n_attrs = 7\n",
    "pickle_list = ['ipapp']   # list of pickled attrs\n",
    "del_cols = []  # attrs to be deleted in final train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = 0   \n",
    "mmap = np.memmap(r'./data/mmap_train.mmp', dtype='float32', mode='w+', shape=(split_train, n_attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_attrs(fname, data_dir='./data/'):\n",
    "    fname = data_dir + fname + '.pkl'\n",
    "    print('loading {}... '.format(fname))\n",
    "    return pd.read_pickle(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ./data/ipapp.pkl... \n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "columns = []\n",
    "for pkl in pickle_list:  \n",
    "    temp = load_attrs(pkl)\n",
    "\n",
    "    columns +=[x for x in temp.columns if x not in del_cols]  \n",
    "    \n",
    "    cols_idx = [temp.columns.tolist().index(x) for x in temp.columns if x not in del_cols]  \n",
    "    temp = temp.iloc[start_skip:split_train, cols_idx]  \n",
    "\n",
    "    ei = temp.values.shape[1]  \n",
    "    \n",
    "    # Assign value to memmap\n",
    "    mmap[:, si:si+ei] = temp.values  \n",
    "    si += ei  \n",
    "\n",
    "    del temp  \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, only cols [0,1] of mmap is filled. Memmap should be filled with existing features before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmap.flush()\n",
    "del mmap\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmap = np.memmap(r'./data/mmap_train.mmp', dtype='float32', mode='r', shape=(split_train, n_attrs))\n",
    "\n",
    "# Only write data we wants to memory. \n",
    "train = np.array(mmap[start_skip:-val_size])\n",
    "val = np.array(mmap[-val_size:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and val are numpy arrays now. Note that mmap should have col 2 -> 6 filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.74400e+03 9.00000e+00]\n",
      " [1.19901e+05 9.00000e+00]\n",
      " [7.22870e+04 2.10000e+01]\n",
      " ...\n",
      " [1.24611e+05 1.20000e+01]\n",
      " [2.79480e+04 1.20000e+01]\n",
      " [5.31400e+03 2.80000e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(_train[:,0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(_train[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = _train[:, columns.index('is_attributed')]\n",
    "y_val = _val[:, columns.index('is_attributed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using what is read from memmap (ndarray) in LGB\n",
    "\n",
    "use_columns = [...]\n",
    "use_columns_idxs = [columns.index(x) for x in use_columns]\n",
    "\n",
    "d_train = train[:, use_columns_idxs]\n",
    "xgtrain = lgb.Dataset(d_train, label=y_train, **dataset_params)\n",
    "d_val = val[:, use_columns_idxs]\n",
    "xgvalid = lgb.Dataset(d_val, label=y_val, reference=xgtrain, **dataset_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
